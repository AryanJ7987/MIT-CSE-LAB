{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f4f152-c8da-4c30-9bc2-c4f6d9db2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.8054, 0.7298, 0.2189, 0.0039, 0.6389, 0.3405],\n",
      "        [0.6491, 0.0056, 0.0038, 0.9187, 0.2678, 0.2995],\n",
      "        [0.0470, 0.1812, 0.7460, 0.6277, 0.4716, 0.5974],\n",
      "        [0.0076, 0.3089, 0.8172, 0.5789, 0.1826, 0.5077],\n",
      "        [0.1124, 0.8974, 0.3809, 0.4848, 0.3776, 0.2550],\n",
      "        [0.1793, 0.7201, 0.1076, 0.8433, 0.0942, 0.0128]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.8054, 0.7298, 0.2189, 0.0039, 0.6389, 0.3405],\n",
      "          [0.6491, 0.0056, 0.0038, 0.9187, 0.2678, 0.2995],\n",
      "          [0.0470, 0.1812, 0.7460, 0.6277, 0.4716, 0.5974],\n",
      "          [0.0076, 0.3089, 0.8172, 0.5789, 0.1826, 0.5077],\n",
      "          [0.1124, 0.8974, 0.3809, 0.4848, 0.3776, 0.2550],\n",
      "          [0.1793, 0.7201, 0.1076, 0.8433, 0.0942, 0.0128]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[[3.3867, 3.4356, 3.8971, 4.1659],\n",
      "          [2.7664, 4.1880, 4.6142, 4.4518],\n",
      "          [3.4985, 5.0230, 4.6672, 4.0833],\n",
      "          [3.5313, 5.1390, 3.8670, 3.3368]]]])\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 1\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "#Perform the convolution\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511bcc99-f541-4731-a41c-fbf509bb3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape using nn.Conv2d: torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define input image\n",
    "image = torch.rand(1, 1, 6, 6)  # Input shape: (batch_size, channels, height, width)\n",
    "\n",
    "# Define convolutional layer with 3 output channels\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "\n",
    "# Apply convolution\n",
    "output = conv_layer(image)\n",
    "\n",
    "print(\"Output shape using nn.Conv2d:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4e2af5-31e8-4be9-85d5-dbbd75e46711",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Perform convolution using functional API\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimage, weight\u001b[38;5;241m=\u001b[39mkernel, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape using functional API:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define kernel\n",
    "kernel = torch.ones(3, 3)\n",
    "\n",
    "# Add batch and channel dimensions to the kernel\n",
    "kernel = kernel.unsqueeze(0).unsqueeze(0)\n",
    "image = torch.rand(1, 1, 6, 6)  \n",
    "# Perform convolution using functional API\n",
    "output = F.conv2d(input=image, weight=kernel, stride=1, padding=0)\n",
    "\n",
    "print(\"Output shape using functional API:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3c49a-1546-403c-a0ec-3b74ef5dd7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbda596-0289-4baa-9cd6-4148eeb7e70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ca572-4ad6-41b5-b8e3-dfc53b427387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
