{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f4f152-c8da-4c30-9bc2-c4f6d9db2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.8054, 0.7298, 0.2189, 0.0039, 0.6389, 0.3405],\n",
      "        [0.6491, 0.0056, 0.0038, 0.9187, 0.2678, 0.2995],\n",
      "        [0.0470, 0.1812, 0.7460, 0.6277, 0.4716, 0.5974],\n",
      "        [0.0076, 0.3089, 0.8172, 0.5789, 0.1826, 0.5077],\n",
      "        [0.1124, 0.8974, 0.3809, 0.4848, 0.3776, 0.2550],\n",
      "        [0.1793, 0.7201, 0.1076, 0.8433, 0.0942, 0.0128]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.8054, 0.7298, 0.2189, 0.0039, 0.6389, 0.3405],\n",
      "          [0.6491, 0.0056, 0.0038, 0.9187, 0.2678, 0.2995],\n",
      "          [0.0470, 0.1812, 0.7460, 0.6277, 0.4716, 0.5974],\n",
      "          [0.0076, 0.3089, 0.8172, 0.5789, 0.1826, 0.5077],\n",
      "          [0.1124, 0.8974, 0.3809, 0.4848, 0.3776, 0.2550],\n",
      "          [0.1793, 0.7201, 0.1076, 0.8433, 0.0942, 0.0128]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[[3.3867, 3.4356, 3.8971, 4.1659],\n",
      "          [2.7664, 4.1880, 4.6142, 4.4518],\n",
      "          [3.4985, 5.0230, 4.6672, 4.0833],\n",
      "          [3.5313, 5.1390, 3.8670, 3.3368]]]])\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 1\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "#Perform the convolution\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511bcc99-f541-4731-a41c-fbf509bb3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output image shape: torch.Size([1, 1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define input image and kernel\n",
    "image = torch.rand(1, 1, 6, 6)  # (batch_size, channels, height, width)\n",
    "kernel = torch.ones(1, 1, 3, 3)  # (out_channels, in_channels, kernel_height, kernel_width)\n",
    "\n",
    "# Define stride and padding\n",
    "stride = 1\n",
    "padding = 5\n",
    "\n",
    "# Perform convolution\n",
    "outimage = F.conv2d(image, kernel, stride=stride, padding=padding)\n",
    "\n",
    "# Print output image shape\n",
    "print(\"Output image shape:\", outimage.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e2af5-31e8-4be9-85d5-dbbd75e46711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
